## 待完成功能


**注意: 不一定会做，只是有所考虑**

- [ ] 爬虫操作
    - [ ] 创建定时任务定时启动爬虫
        - [ ] 每隔一定时间启动一个
        - [ ] 定时执行
        - [ ] 当任务存在时不执行新任务
        - [ ] 当前爬虫最大任务数量
        - [ ] 关闭爬虫（SIGKILL）
    - [ ] 调研 Scrapy 拓展注入，可以在 ScrapyCW 中注入 Scrapy 拓展
    - [ ] 允许用户直接通过 Scrapy Telnet 操作爬虫任务
- [ ] 日志解析
    - [ ] 通过命令行传入文件解析日志（可以输入日志格式）
    - [ ] 通过 Web 上传文件解析日志（可以输入日志格式）
- [ ] Scrapycw 国际化（i18n）
- [ ] 多机部署
- [ ] 优化
    - [ ] 优化 INIT_EACH_RUN 配置
    - [ ] 添加 Telnet 工具类单元测试
    - [ ] 添加日志解析工具类单元测试
    - [ ] 考虑关闭爬虫监听由轮询修改为 Scrapy 拓展方式优缺点，是否合适
- [ ] Web 服务
    - [ ] 爬虫操作
        - [ ] 获取项目列表
        - [ ] 获取爬虫列表
        - [ ] 启动爬虫
        - [ ] 关闭爬虫
        - [ ] 暂停爬虫
        - [ ] 恢复爬虫
        - [ ] 获取爬虫任务列表
        - [ ] 获取爬虫详细的执行状态
    - [ ] 可以覆盖 Scrapycw Settings 配置（优先级大于项目内 settings, 大于默认 settgins）
    - [ ] 移动端适配
    - [ ] 在一定条件下，通过 WebHooks 将爬虫运行信息发送到指定 URL（发送Email、钉钉、微信、自定义接口）
    - [ ] 创建爬虫启动模板
    - [ ] 创建爬虫组，可以一键执行多个爬虫/模板
    - [ ] 权限配置，必须登录才能访问
    - [ ] 添加 Pipeline、下载中间件、拓展等（用户可以自定义）

## 已完成功能

- [x] Web 服务
    - [x] 启动/关闭/重启 Web 服务
        - [x] 支持 Windows
        - [x] 支持 MacOS
        - [x] 支持创建守护进程
    - [x] ping 接口，判断服务是否启动成功
- [x] 爬虫操作
    - [x] 获取 Project 列表
    - [x] 获取爬虫列表
    - [x] 启动爬虫
        - [x] 支持 Windows
        - [x] 支持 MacOS
    - [x] 关闭爬虫（SIGTERM）
    - [x] 暂停爬虫
    - [x] 恢复爬虫
    - [x] 获取爬虫任务列表
        - [x] 获取运行中的爬虫
        - [x] 获取已关闭的爬虫
    - [x] 获取爬虫详细的执行状态
- [x] 日志解析，解析 Scrapy 日志
- [x] Scrapy Telnet 操作
